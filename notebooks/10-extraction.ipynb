{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracción\n",
    "\n",
    "Leemos todos los PDFs y extraemos los metadatos, el texto y las imágenes. Así no tengo que laburar con PDFs que es más molesto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from pypdf import PdfReader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"../data\")\n",
    "EXTRACT_PATH = Path(\"../data-extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(pages):\n",
    "    # join pages to one string\n",
    "    text = \"\\n\".join([page.extract_text() for page in pages])\n",
    "    text = text.strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(filename, pages):\n",
    "    images = [file.image for page in pages for file in page.images]\n",
    "\n",
    "    # remove QR images 370x370 and 330x330\n",
    "    images = [image for image in images if image.size != (370, 370) and image.size != (330, 330)]\n",
    "\n",
    "    # remove duplicates data with hashes (exact match)\n",
    "    hashes = set()\n",
    "    for i, image in enumerate(images):\n",
    "        hash = hashlib.md5(image.tobytes()).hexdigest()\n",
    "        if hash in hashes:\n",
    "            images[i] = None\n",
    "        else:\n",
    "            hashes.add(hash)\n",
    "\n",
    "    # save images\n",
    "    image_paths = []\n",
    "    if len(images) > 0:\n",
    "        folder = EXTRACT_PATH / filename\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "        for i, image in enumerate(images):\n",
    "            if image is not None:\n",
    "                image_path = folder / f\"{i}.png\"\n",
    "                image.save(image_path)\n",
    "                image_paths.append(str(image_path.resolve()))\n",
    "\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8411/8411 [6:08:40<00:00,  2.63s/it]  \n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(DATA_PATH)\n",
    "samples = []\n",
    "\n",
    "for filename in tqdm(files):\n",
    "    if not filename.endswith(\".pdf\"):\n",
    "        continue\n",
    "\n",
    "    filepath = DATA_PATH / filename\n",
    "    reader = PdfReader(filepath)\n",
    "\n",
    "    text = process_text(reader.pages)\n",
    "    images = process_images(filename, reader.pages)\n",
    "\n",
    "    samples.append({\n",
    "        \"filename\": filename,\n",
    "        \"size\": os.path.getsize(filepath),\n",
    "        \"pages\": len(reader.pages),\n",
    "        \"text\": text,\n",
    "        \"images\": images,\n",
    "    })\n",
    "\n",
    "with open(EXTRACT_PATH / \"samples.json\", \"w\") as f:\n",
    "    json.dump(samples, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ParaiSUR-FY4onnAP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
